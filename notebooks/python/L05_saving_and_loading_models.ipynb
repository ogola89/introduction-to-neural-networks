{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_tvPdyfA-BL"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "0O_LFhwSBCjm"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-3Pry4jh1-E"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rses-dl-course/rses-dl-course.github.io/blob/master/notebooks/python/L06_saving_and_loading_models.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/rses-dl-course/rses-dl-course.github.io/blob/master/notebooks/python/L06_saving_and_loading_models.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NxjpzKTvg_dd"
   },
   "source": [
    "# Lab 05: Saving and Loading Models\n",
    "\n",
    "In this lab we will learn how we can take a trained model, save it, and then load it back to keep training it or use it to perform inference. We will train a classifier to classify images of cats and dogs, just like we did in the previous lesson. This time however, we will be adding checkpoints while training. We will then restore this model from checkpoint, use it to perform predictions, and then continue to train the model. Finally, we will save our trained model as a TensorFlow SavedModel and then we will download it to a local disk, so that it can later be used for deployment in different platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "crU-iluJIEzw"
   },
   "source": [
    "## Concepts that will be covered in this Colab\n",
    "\n",
    "1. Saving checkpoints while training the model\n",
    "2. Saving models in the TensorFlow SavedModel format\n",
    "3. Loading models\n",
    "4. Download models to Local Disk\n",
    "\n",
    "Before starting this Colab, you should reset the Colab environment by selecting `Runtime -> Reset all runtimes...` from menu above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RVsYZLEpEWs"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGNpmn43C0O6"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amfzqn1Oo7Om"
   },
   "source": [
    "# Part 1: Load the Cats vs. Dogs Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)\n",
    "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
    "\n",
    "train_image_generator      = ImageDataGenerator(rescale=1./255)  # Generator for our training data\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)  # Generator for our validation data\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# The images in the Dogs vs. Cats dataset are not all the same size, so we'll \n",
    "# re-format the image resoluation to 150x150 just like our previous exercise.\n",
    "IMAGE_RES = 150\n",
    "\n",
    "train_batches = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMAGE_RES,IMAGE_RES), #(150,150)\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "validation_batches = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              shuffle=True,\n",
    "                                                              target_size=(IMAGE_RES,IMAGE_RES), #(150,150)\n",
    "                                                              class_mode='binary')\n",
    "\n",
    "class_names = np.array([\"cats\", \"dogs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Train the Model with checkpoints\n",
    "\n",
    "We will use the same model as in the beginning of the previous exercise to quickly put together a cats and dog classiffier. This time however, we will add checkpointing so that the model weights are saved as it is being trained.\n",
    "\n",
    "Checkpointing as especially important with larger models that takes a long time to train. It can save from having to train from scratch should something go wrong (e.g. power cuts, system crash, etc.) and means you can go back to a specific stage of training and refine your hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Createa a [`ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) which will be used as the callback when we train the model. By default, it will save after every epoch but the `save_freq=` parameter can used to specify how frequently to save.\n",
    "\n",
    "Named formatting can be used when specifying the path of our checkpoint files, in this case `cp-epoch{epoch:04d}-val_loss{val_loss:.2f}.ckpt` will record the epoch and validation loss at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"catsdogs_checkpoint/cp-epoch{epoch:04d}-val_loss{val_loss:.2f}.ckpt\"  \n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train the model for only 6 epochs for now, notice that `cp_callback` is added to the `callbacks` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 6\n",
    "history = model.fit(\n",
    "    train_batches,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_batches,\n",
    "    callbacks=[cp_callback], # Add the ModelCheckpoint to the list of training callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the checkpoint files are saved in the `catsdogs_checkpoint` directory as we specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kb__ZN8uFn-D"
   },
   "source": [
    "## Check the predictions\n",
    "\n",
    "Below is an example function that takes the first batch from a provided dataset and use it to perform prediction on the provided model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the first batch from validation_batches set\n",
    "image_batch, label_batch = next(iter(validation_batches))\n",
    "\n",
    "\n",
    "def check_predictions(model):\n",
    "    \"\"\"\n",
    "    Function for visualising predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform prediction on the batch\n",
    "    predicted_batch = model.predict(image_batch)\n",
    "    predicted_batch = tf.squeeze(predicted_batch).numpy()\n",
    "    predicted_ids = np.argmax(predicted_batch, axis=-1)\n",
    "    predicted_class_names = class_names[predicted_ids]\n",
    "    print(\"Predicted class names: \", predicted_class_names)\n",
    "    \n",
    "    # Print out label and predictions as a comparison\n",
    "    print(\"Labels: \", label_batch)\n",
    "    print(\"Predicted labels: \", predicted_ids)\n",
    "    \n",
    "    # Visually plot this result\n",
    "    plt.figure(figsize=(10,9))\n",
    "    for n in range(30):\n",
    "      plt.subplot(6,5,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "      color = \"blue\" if predicted_ids[n] == label_batch[n] else \"red\"\n",
    "      plt.title(predicted_class_names[n].title(), color=color)\n",
    "      plt.axis('off')\n",
    "    _ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_predictions(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yXole25Z799G"
   },
   "source": [
    "# Part 4:  Load from previously saved checkpoint\n",
    "\n",
    "We will now load a model checkpoint we just saved into a new model called `reloaded`. When we created `ModelCheckpoint` the parameter `save_weights_only=True` was specified, this means only the weights matrix was saved. Hence we also need to re-define our model graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rx-z3Qwx5RnB"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "reloaded = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "# Compile the model\n",
    "reloaded.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxDl2vPkf2ST"
   },
   "source": [
    "As it's a new model, it performs pooly when running a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFljA-Hd85Tu"
   },
   "outputs": [],
   "source": [
    "check_predictions(reloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load from the latest checkpoint by using the function `tf.train.latest_checkpoint()` or use `tf.train.load_checkpoint()` to load a specific file. The resulting weights matrix can then be loaded to our `reloaded` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets a weights matrix from the checkpoint\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "# Loads to our model\n",
    "reloaded.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the prediction again, it will give the same result as our previously trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_predictions(reloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKunO4soA4Dm"
   },
   "source": [
    "# Keep Training\n",
    "\n",
    "Besides making predictions, we can also take our `reloaded` model and keep training it. To do this, you can just train the `reloaded` as usual, using the `.fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEv-fnHEAplx"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "history = reloaded.fit(train_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the prediction again to see the results of further training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_predictions(reloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5OKoZaAHFH_s"
   },
   "source": [
    "# Part 5: Export as SavedModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3V47IwQbFTYT"
   },
   "source": [
    "You can also export a whole model to the TensorFlow SavedModel format. SavedModel is a standalone serialization format for Tensorflow objects, supported by TensorFlow serving as well as TensorFlow implementations other than Python. A SavedModel contains a complete TensorFlow program, including weights and computation. It does not require the original model building code to run, which makes it useful for sharing or deploying (with TFLite, TensorFlow.js, TensorFlow Serving, or TFHub).\n",
    "\n",
    "The SavedModel files that were created contain:\n",
    "\n",
    "* A TensorFlow checkpoint containing the model weights.\n",
    "* A SavedModel proto containing the underlying Tensorflow graph. Separate graphs are saved for prediction (serving), train, and evaluation. If the model wasn't compiled before, then only the inference graph gets exported.\n",
    "* The model's architecture config, if available.\n",
    "\n",
    "\n",
    "Let's save our original `model` as a TensorFlow SavedModel. To do this we will use the `model.save()` function. This functions takes in the model we want to save and the path to the folder where we want to save our model.\n",
    "\n",
    "This function will create a folder where you will find an `assets` folder, a `variables` folder, `keras_metadata.pb` and the `saved_model.pb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtpeKMfoGXrj"
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "export_path_sm = \"./{}\".format(int(t))\n",
    "print(export_path_sm)\n",
    "\n",
    "model.save(export_path_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5h6B1wITlu-9"
   },
   "outputs": [],
   "source": [
    "!ls {export_path_sm}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ktpsqHxJPIQW"
   },
   "source": [
    "# Part 6: Load SavedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0FDcCn9ncDb"
   },
   "source": [
    "Now, let's load our SavedModel and use it to make predictions. We use the `tf.saved_model.load()` function to load our SavedModels. The object returned by `tf.saved_model.load` is 100% independent of the code that created it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7_PM7lofG2V"
   },
   "outputs": [],
   "source": [
    "reloaded_sm = tf.saved_model.load(export_path_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "esEODdtM0kHB"
   },
   "source": [
    "Now, let's use the `reloaded_sm` (reloaded SavedModel) to make predictions on a batch of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpQldy_bm3Ty"
   },
   "outputs": [],
   "source": [
    "# Prediction from the saved model as a comparison\n",
    "result_batch = model.predict(image_batch)\n",
    "\n",
    "# Prediction from the loaded model\n",
    "reload_sm_result_batch = reloaded_sm(image_batch, training=False).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65upCyVN0u3Q"
   },
   "source": [
    "We can check that the reloaded SavedModel and the previous model give the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hoCwmkGznR_0"
   },
   "outputs": [],
   "source": [
    "(abs(result_batch - reload_sm_result_batch)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxuETjjs01pL"
   },
   "source": [
    "As we can see, the result is 0.0, which indicates that both models made the same predictions on the same batch of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Nom-ka0yuqB"
   },
   "source": [
    "# Part 7: Loading the SavedModel as a Keras Model\n",
    "\n",
    "The object returned by `tf.saved_model.load` is not a Keras object (i.e. doesn't have `.fit`, `.predict`, `.summary`, etc. methods). Therefore, you can't simply take your `reloaded_sm` model and keep training it by running `.fit`. To be able to get back a full keras model from the Tensorflow SavedModel format we must use the `tf.keras.models.load_model` function. This function will work the same as before, except now we pass the path to the folder containing our SavedModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vi1jaqh8yvt6"
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "export_path_sm = \"./{}\".format(int(t))\n",
    "print(export_path_sm)\n",
    "model.save(export_path_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1VPE2_QQGmAP"
   },
   "outputs": [],
   "source": [
    "reload_sm_keras = tf.keras.models.load_model(\n",
    "  export_path_sm,\n",
    "  custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "\n",
    "reload_sm_keras.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thTbiHE72GL4"
   },
   "source": [
    "Now, let's use the `reloaded_sm_keras` (reloaded Keras model from our SavedModel) to make predictions on a batch of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-0oCJrNLKdKj"
   },
   "outputs": [],
   "source": [
    "result_batch = model.predict(image_batch)\n",
    "reload_sm_keras_result_batch = reload_sm_keras.predict(image_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jUQaxzFj2Q8k"
   },
   "source": [
    "We can check that the reloaded Keras model and the previous model give the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJCD9JJxKg9F"
   },
   "outputs": [],
   "source": [
    "(abs(result_batch - reload_sm_keras_result_batch)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFa6jNc4PW9F"
   },
   "source": [
    "# Part 8:  Download your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2W_y1qMVQeCm"
   },
   "source": [
    "You can download the SavedModel to your local disk by creating a zip file. We wil use the `-r` (recursice) option to zip all subfolders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPRFoU1xPCGF"
   },
   "outputs": [],
   "source": [
    "!zip -r model.zip {export_path_sm}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MBZL85RsQBTj"
   },
   "source": [
    "The zip file is saved in the current working directory. You can see what the current working directory is by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALP-DfwSQRL8"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IR89aU-SRmsL"
   },
   "source": [
    "Once the file is zipped, you can download  it to your local disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOXYrlDkNjKQ"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from google.colab import files\n",
    "  files.download('./model.zip')\n",
    "except ImportError:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzLutxq_SeLQ"
   },
   "source": [
    "The `files.download` command will  search for files in your current working directory. If the file you want to download is in a directory other than the current working directory, you have to include the path to the directory where the file is located."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Lab 05: Saving and Loading Models",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}