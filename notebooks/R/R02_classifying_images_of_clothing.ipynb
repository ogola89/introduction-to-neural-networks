{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R02_classifying_images_of_clothing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vasWnqRgy1H4"
      },
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Lab 02 Classifying Images of Clothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rses-dl-course/rses-dl-course.github.io/blob/master/notebooks/R/R02_classifying_images_of_clothing.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/rses-dl-course/rses-dl-course.github.io/blob/master/notebooks/R/R02_classifying_images_of_clothing.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "In this tutorial, we'll build and train a neural network to classify images of clothing, like sneakers and shirts.\n",
        "\n",
        "It's okay if you don't understand everything. This is a fast-paced overview of a complete TensorFlow program, with explanations along the way. The goal is to get the general sense of a TensorFlow project, not to catch every detail.\n",
        "\n",
        "This guide uses the [Keras](https://www.tensorflow.org/guide/keras) R library, a high-level API to build and train models in TensorFlow [through R](https://keras.rstudio.com/). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnqM3m43hfnN"
      },
      "source": [
        "## Install and import dependencies\n",
        "\n",
        "We'll need to install the `keras` R package which also includes the example datasets we'll be working with. \n",
        "\n",
        "Alternatively, there is also the option of installing the [`tfdatasets`](https://tensorflow.rstudio.com/guide/tfdatasets/introduction/) package. This package is an R interface to TensorFlow datasets and provides access to the Dataset API. The TensorFlow Dataset API provides various facilities for **creating scalable input pipelines for TensorFlow models**, including high-level convenience functions for easy integration with Keras and access to Tensorflow example datasets.\n",
        "\n",
        "We'll also install a couple more packages that we will use for plotting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkKE30iyj2PE"
      },
      "source": [
        "install.packages(c(\"keras\", \"tidyr\", \"ggplot2\", \"cowplot\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz7nYfD_0plK"
      },
      "source": [
        "Once installed, load the library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jb9qpKD6qQI"
      },
      "source": [
        "library(keras)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Import the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "This tutorial uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset, which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 $\\times$ 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\" width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Fashion MNIST is intended as a drop-in replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset—often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc) in an identical format to the articles of clothing we'll use here.\n",
        "\n",
        "This guide uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n",
        "\n",
        "We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from the [Keras R package](https://keras.rstudio.com/reference/dataset_fashion_mnist.html) using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4rt08jnjahP"
      },
      "source": [
        "fashion_mnist <- dataset_fashion_mnist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exrrQGep60FQ"
      },
      "source": [
        "str(fashion_mnist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "Loading the dataset returns a list, containing two elements, **`train`** which contains the *training dataset* and **`test`** containing the *test dataset*.\n",
        "\n",
        "* The model is trained using `train`.\n",
        "* The model is tested against `test`.\n",
        "\n",
        "\n",
        "The images in each dataset (`x`) are 28 $\\times$ 28 arrays, with pixel values in the range `[0, 255]`. The *labels* (`y`) are an array of integers, in the range `[0, 9]`. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "**Each image is mapped to a single label.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qna5bbSN2_iA"
      },
      "source": [
        "Lets split this list into four separate arrays: The `train_images` and `train_labels` arrays are the **training set** — the data the model uses to learn. The model is tested against the **test set**: the `test_images`, and `test_labels` arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAC8Dqwh3RYU"
      },
      "source": [
        "c(train_images, train_labels) %<-% fashion_mnist$train\n",
        "c(test_images, test_labels) %<-% fashion_mnist$test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYlzUP3H3x4G"
      },
      "source": [
        "\n",
        "Since the *class names* are not included with the dataset, we can store them in a character vector to use later when plotting the images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RifKaS0Cmvs5"
      },
      "source": [
        "class_names <- c('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal',      'Shirt',   'Sneaker', 'Bag',   'Ankle boot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "### Explore the data\n",
        "\n",
        "Let's explore the format of the dataset before training the model. The following shows there are 60,000 images in the training set, with each image represented as 28 x 28 pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWQ0N6FZ4jAi"
      },
      "source": [
        "dim(train_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx5fzEKhBAnt"
      },
      "source": [
        "The pixel values across all images range between 0 and 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpy3X305Ab34"
      },
      "source": [
        "range(train_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pihlmQ5J4itA"
      },
      "source": [
        "Likewise, there are 60,000 labels in the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1JqmCyxAAHT"
      },
      "source": [
        "dim(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhWuWmklAJ0X"
      },
      "source": [
        "Each label is an integer between 0 and 9:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfZ9RgucALfZ"
      },
      "source": [
        "train_labels %>% unique() %>% sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdDk7WVVBPqD"
      },
      "source": [
        "There are 10,000 images in the test set. Again, each image is represented as 28 x 28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va-GAS5wBSkH"
      },
      "source": [
        "dim(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGN1cRPXBfI7"
      },
      "source": [
        "And the test set contains 10,000 images labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YmGbSGKBYqh"
      },
      "source": [
        "dim(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "The data must be preprocessed before training the network. The value of each pixel in the image data is an integer in the range `[0,255]`. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zfsrf9vBcF8"
      },
      "source": [
        "library(tidyr)\n",
        "library(ggplot2)\n",
        "\n",
        "plot_fashionmnist_image <- function(image){\n",
        "  image <- as.data.frame(image)\n",
        "  colnames(image) <- seq_len(ncol(image))\n",
        "  image$y <- seq_len(nrow(image))\n",
        "  image <- gather(image, \"x\", \"value\", -y)\n",
        "  image$x <- as.integer(image$x)\n",
        "\n",
        "  ggplot(image, aes(x = x, y = y, fill = value)) +\n",
        "    geom_tile() +\n",
        "    scale_fill_gradient(low = \"white\", high = \"black\", na.value = NA) +\n",
        "    scale_y_reverse() +\n",
        "    theme_minimal() +\n",
        "          theme(panel.grid = element_blank(), \n",
        "                axis.text = element_blank(),\n",
        "                axis.title = element_blank(),\n",
        "                aspect.ratio = 1)\n",
        "}\n",
        "\n",
        "plot_fashionmnist_image(train_images[1,,])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSQBjqhlcQUB"
      },
      "source": [
        "For the model to work properly, these values need to be normalized to the range `[0,1]`. To perform the conversion we can divide each array by 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ksdltMc-2J9"
      },
      "source": [
        "train_images <- train_images/255\n",
        "test_images <- test_images/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCsSbDQHBxJV"
      },
      "source": [
        "### Explore the processed data\n",
        "\n",
        "We can check that pixel values have been successfully processed by checking the range of values in each array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8O2zsxVA7R6"
      },
      "source": [
        "range(train_images)\n",
        "range(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIQbEiJGXM-q"
      },
      "source": [
        "To verify that the data appears correctly labelled, let's also display the first 25 images from the training set as well as the class name below each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOPXPfd3a7zc"
      },
      "source": [
        "par(mfcol=c(5,5))\n",
        "par(mar=c(0, 0, 1.5, 0), xaxs='i', yaxs='i')\n",
        "for (i in 1:25) { \n",
        "  img <- train_images[i, , ]\n",
        "  img <- t(apply(img, 2, rev)) \n",
        "  image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = 'n', yaxt = 'n',\n",
        "        main = paste(class_names[train_labels[i] + 1]))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KvH_wY3dw9v"
      },
      "source": [
        "We’re ready to build and train the network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "Building the neural network requires configuring the layers of the model, then compiling the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Setup the layers\n",
        "\n",
        "The basic building block of a neural network is the *layer*. A layer extracts a representation from the data fed into it. Hopefully, a series of connected layers results in a representation that is meaningful for the problem at hand.\n",
        "\n",
        "Much of deep learning consists of chaining together simple layers. Most layers, like Keras `layer_dense`, have internal parameters which are adjusted (\"learned\") during training.\n",
        "\n",
        "The network we want to build has three layers:\n",
        "\n",
        "* **input** `layer_flatten()` — This layer transforms the images from a 2d-array of 28 $\\times$ 28 pixels, to a 1d-array of 784 pixels (28\\*28). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn, as it only reformats the data.\n",
        "\n",
        "* **\"hidden\"** `layer_dense()`— A densely connected layer of 128 neurons and ReLu activation. Each neuron (or node) takes input from all 784 nodes in the previous layer, weighting that input according to hidden parameters which will be learned during training, and outputs a single value to the next layer.\n",
        "\n",
        "* **output** `layer_dense()` — A 10-node ***softmax*** layer, with each node representing a class of clothing. As in the previous layer, each node takes input from the 128 nodes in the layer before it. Each node weights the input according to learned parameters, and then outputs a value in the range `[0, 1]`, representing the probability that the image belongs to that class. The sum of all 10 node values is 1.\n",
        "\n",
        "**The code below already has the first `flatten` layer, add the other two `Dense` layers to complete our model.**\n",
        "* The hidden layer uses an activation function, you'll need to add an extra parameter `activation=\"relu\"`.\n",
        "* The output layer also uses an activation function, you'll need to add an extra parameter `activation=\"softmax\"`.\n",
        "\n",
        "For more details on implementing these layers, have a look at the [R keras core layer documentation](https://keras.rstudio.com/reference/index.html#section-core-layers)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2KNUkEwb4am"
      },
      "source": [
        "model <- keras_model_sequential()\n",
        "model %>%\n",
        "  # Input layer\n",
        "  layer_flatten(input_shape = c(28, 28)) %>%\n",
        "  # TODO: Add dense hidden layer\n",
        "    \n",
        "  # TODO: Add dense output layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saRWacslk40-"
      },
      "source": [
        "#### Exercise 2.1 Solution (5 mins)\n",
        "\n",
        "The solution for the exercise can be found [here](https://colab.research.google.com/github/rses-dl-course/rses-dl-course.github.io/blob/master/notebooks/R/solutions/E.2.1.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPmr2w9NpTah"
      },
      "source": [
        "## Compile the model\n",
        "\n",
        "Before the model is ready for training, it needs a few more settings. These are added during the model’s compile step:\n",
        "\n",
        "* Optimizer — This is **how the model is updated** based on the data it sees and its loss function. _Note that here we are specifying the optimiser using a character string. This means the optimiser will be used with default settings. If you need to change any of the default settings (e.g. the learning rate), you would need to use the [function form of the optimiser](https://keras.rstudio.com/reference/optimizer_adam.html)_.\n",
        "* Loss function — This **measures how accurate the model is** during training. We want to minimize this function to “steer” the model in the right direction. Here because our targets are categories and the format of our targets is a one dimensional vector of integers we use [`sparse_categorical_crossentropy`](https://keras.rstudio.com/reference/loss_mean_squared_error.html#section-categorical-crossentropy) as our loss function.\n",
        "* Metrics — Used to **monitor the training and testing steps**. The following example uses accuracy, the fraction of the images that are correctly classified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf52qjBIcUjH"
      },
      "source": [
        "model %>% compile(\n",
        "  optimizer = 'adam', \n",
        "  loss = 'sparse_categorical_crossentropy',\n",
        "  metrics = c('accuracy')\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYE0QUDbqCse"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Training the neural network model requires the following steps:\n",
        "\n",
        "* Feed the training data to the model — in this example, the `train_images` and `train_labels` arrays.\n",
        "* The model learns to associate images and labels.\n",
        "* We ask the model to make predictions about a test set — in this example, the `test_images` array. We verify that the predictions match the labels from the `test_labels` array.\n",
        "\n",
        "#### To start training, call the [`fit`](https://keras.rstudio.com/reference/fit.keras.engine.training.Model.html) method — the model is “fit” to the training data:\n",
        "\n",
        "Some default `fit` settings you should be aware of:\n",
        "- `shuffle = TRUE` which randomizes the order our data is fed into our model each epoch so our model cannot learn anything from the order of the examples.\n",
        "- Model fit proceeds using batches of data. If unspecified, `batch_size` will default to 32\n",
        "- The `epochs = 5` parameter limits training to 5 full iterations of the training dataset, so a total of 5 * 60000 = 300000 examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYhK9iR2cZSB"
      },
      "source": [
        "history <- model %>% fit(train_images, train_labels, epochs = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ2KeSJyqgNa"
      },
      "source": [
        "As the model trains (if your run this locally, does not work with R in google colab notebooks), the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.91 (or 91%) on the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNSiaZ_Bqtpy"
      },
      "source": [
        "## Evaluate Accuracy\n",
        "\n",
        "Next, compare how the model performs on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoR4pJ0GcyXi"
      },
      "source": [
        "score <- model %>% evaluate(test_images, test_labels)\n",
        "cat('Test loss:', score[\"loss\"], \"\\n\")\n",
        "cat('Test accuracy:', score[\"accuracy\"], \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sq0x79Zq9xA"
      },
      "source": [
        "It turns out, the accuracy on the test dataset is a little less than the accuracy on the training dataset. This gap between training accuracy and test accuracy is an example of (very minor) overfitting. Overfitting is when a machine learning model performs worse on new data than on their training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6j6ip884Yg2"
      },
      "source": [
        "## Make predictions and explore\n",
        "\n",
        "With the model trained, we can use it to make predictions about some images. Let's subset the first 32 images and labels from the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPASuh8r-X8b"
      },
      "source": [
        "pred_images <- test_images[1:32 , , ,  drop = FALSE]\n",
        "pred_labels <- test_labels[1:32]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofyosPN0Rz6T"
      },
      "source": [
        "Next we can use use our model and the keras `predict` function to generate some predictions for our image subset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZaXW2FA-uLF"
      },
      "source": [
        "preds_probs <- model %>%\n",
        "  predict(x = pred_images)\n",
        "\n",
        "head(preds_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osSUnZheR3XU"
      },
      "source": [
        "Here, because we used softmax activation on our output layer, the model has calculated the probability associated with each label for each image in our subset and returns a matrix with 10 columns (the number of classes) and 32 rows (the number of images in our subset. Note that we have only printed out the top 6 rows above).\n",
        "\n",
        "To get a class prediction we select the class (column) with the highest probability. We can do that by applying the `which.max` function to each row of our prediction matrix. We also need to subtract 1 from each returned column index because while column indexes are 1 indexed (the first column number is indexed by 1), our classes are 0 indexed (the first class in our data is indexed with 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPK1vkzpQkVL"
      },
      "source": [
        "apply(preds_probs, 1, which.max) - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5NRlUgfTgH5"
      },
      "source": [
        "This prediction approach can be useful if you want to know the probability distribution for each prediction across all classes. However, if you are only interested in the predicted class, there is a shorthand keras function that can return predicted classes instead, `predict_classes`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUh5_bLqAb2g"
      },
      "source": [
        "preds_classes <- model %>%\n",
        "  predict_classes(x = pred_images)\n",
        "\n",
        "preds_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RXmTn3DUTpW"
      },
      "source": [
        "Let's take a look at the first prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3q-M02DUVa9"
      },
      "source": [
        "preds_classes[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AknTqpncUvsV"
      },
      "source": [
        "Let's see what class that is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv_o0P3TUwzM"
      },
      "source": [
        "class_names[preds_classes[1] + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug0h1rMNUfaH"
      },
      "source": [
        "Our model predicts that this image is an **Ankle boot**, or `class_names[10]`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwDVYy-wPhpv"
      },
      "source": [
        "We can graph this to look at the full set of 10 class predictions. First let's write some additional plotting functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuWP9HNDev-0"
      },
      "source": [
        "library(cowplot)\n",
        "\n",
        "# Function to plot bar plot of probabilities across each class\n",
        "plot_preds_bar <- function(probs, label){\n",
        "\n",
        "  plot_data <- data.frame(class = as.factor(0:9), probability = probs, pred_label = FALSE, label = FALSE)\n",
        "  plot_data$pred_label[which.max(probs)] <- TRUE\n",
        "  plot_data$label[label + 1] <- TRUE\n",
        "  plot_data$legend <- \"not predicted - correct\"\n",
        "  plot_data$legend[plot_data$pred_label & plot_data$label] <- \"predicted - correct\"\n",
        "  plot_data$legend[plot_data$pred_label & !plot_data$label] <- \"predicted - incorrect\"\n",
        "  plot_data$legend[plot_data$label & !plot_data$pred_label] <- \"actual - incorrect\"\n",
        "\n",
        "  ggplot(plot_data, aes(x = class, y = probability, fill = legend)) + \n",
        "    geom_bar(stat = \"identity\") +\n",
        "    scale_fill_manual(values = c(\"predicted - correct\" = \"blue\",\n",
        "                                 \"predicted - incorrect\" = \"red\",\n",
        "                                 \"actual - incorrect\" = \"blue\",\n",
        "                                 \"not predicted - correct\" = \"grey\"),\n",
        "                      guide = \"none\") +\n",
        "    theme_classic()\n",
        "}\n",
        "# Function to plot raw image and bar plot of probabilities across each class\n",
        "plot_preds <- function(image, probs, label, class_names){\n",
        "    \n",
        "    pred_label <- which.max(probs) - 1\n",
        "    correct_label <- label == pred_label\n",
        "    title_colour <- if(correct_label){\"blue\"}else{\"red\"}\n",
        "\n",
        "    # create title string\n",
        "    title <- ggdraw() +\n",
        "      draw_label(\n",
        "        paste0(class_names[pred_label + 1], \" \", format(max(probs) * 100, digits = 3), \n",
        "               \"% \", \" (\", class_names[label + 1], \")\"),\n",
        "        fontface = 'bold',\n",
        "        x = 0,\n",
        "        hjust = 0,\n",
        "        color = title_colour) +\n",
        "      theme(plot.margin = margin(0, 0, 0, 7))\n",
        "    \n",
        "    # Generate the two plots\n",
        "    p1 <- plot_fashionmnist_image(image)\n",
        "    p2 <- plot_preds_bar(probs, label)\n",
        "\n",
        "   # Create row of plots\n",
        "   plot_row <- plot_grid(p1, p2)\n",
        "\n",
        "   # Bring together title and row of images\n",
        "   plot_grid(title, plot_row, ncol = 1, rel_heights = c(0.1, 1))\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2r2AqIrPRIf"
      },
      "source": [
        "options(repr.plot.width = 10, repr.plot.height = 5)\n",
        "i <- 1\n",
        "plot_preds(pred_images[i,,], preds_probs[i,], pred_labels[i], class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7KiEpduQ5hT"
      },
      "source": [
        "i <- 5\n",
        "plot_preds(pred_images[i,,], preds_probs[i,], pred_labels[i], class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiCR0dX_NpJF"
      },
      "source": [
        "options(repr.plot.width = 14, repr.plot.height = 8)\n",
        "  j <- 16\n",
        "  plot_list <- as.list(vector(length = j))\n",
        "  for(i in 1:j){\n",
        "    plot_list[[i]]<- plot_preds(pred_images[i,,], preds_probs[i,], \n",
        "                                pred_labels[i], class_names)\n",
        "  }\n",
        "  plot_grid(plotlist = plot_list, ncol = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dz4uzty6Soq"
      },
      "source": [
        "Finally, use the trained model to make a prediction about a single image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKsTuVK46SCY"
      },
      "source": [
        "image <- test_images[1,,,drop = FALSE]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLZk0hrUFb6L"
      },
      "source": [
        "preds_class_single <- model %>% predict_classes(image)\n",
        "\n",
        "preds_class_single"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvJQ1pRrl5vf"
      },
      "source": [
        "# Exercise 2.2\n",
        "\n",
        "Experiment with different models and see how the accuracy results differ. In particular change the following parameters:\n",
        "*   Set training epochs set to 1\n",
        "*   Number of neurons in the Dense layer following the Flatten one. For example, go really low (e.g. 10) in ranges up to 512 and see how accuracy changes\n",
        "*   Add additional Dense layers between the Flatten and the final `Dense(10)`, experiment with different units in these layers\n",
        "*   Don't normalize the pixel values, and see the effect that has"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYovvwfQbkAZ"
      },
      "source": [
        "\n",
        "# Exercise 2.3 - CIFAR-10 Dataset (15 mins)\n",
        "\n",
        "Let's apply what we've learned to another dataset.The [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "As our input is a colour image, we have now 3 values per pixel. When flattened, our input array is is 3072 long ($32\\times32\\times3$). \n",
        "\n",
        "* What happens when you use the same network as above?\n",
        "* What is the best accuracy that you can achieve?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQjFzS02bkAZ"
      },
      "source": [
        "The dataset is also available through the `Keras R package`. We can load it using [**`dataset_cifar10()`**](https://keras.rstudio.com/reference/dataset_cifar10.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPhU1aQol_gK"
      },
      "source": [
        "cifar10 <- dataset_cifar10()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9PrvgtTsFJ3"
      },
      "source": [
        "Let's inspect the data. It's similar in structure to the fashion MNIST dataset but the images (`x`) are now 4 dimensional arrays, with a dimension for channels (RGB). The size of the images is **32 $\\times$ 32**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgTRraChmPpo"
      },
      "source": [
        "str(cifar10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXkMLpJyslFh"
      },
      "source": [
        "The number of labels is again 10 and each label (0-9) maps on to one of the following classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsyktAJZnsUB"
      },
      "source": [
        "cifar_labels <- c('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog',\n",
        " 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e5dhXIZs4WL"
      },
      "source": [
        "Let's create a plotting function that can accomodate the RGB nature of the images and explore the first 21 images in the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUIV6R36pHmY"
      },
      "source": [
        "plot_raster_image <- function(image_array, label, max_value = 1, max_dim = 3){\n",
        "  image_array %>%\n",
        "  array_reshape(dim = c(dim(.)[1:max_dim])) %>%\n",
        "  as.raster(max = max_value) %>%\n",
        "  plot()\n",
        "  title(main = label)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRGTfaeLpbyx"
      },
      "source": [
        "# set plotting options\n",
        "options(repr.plot.width = 16, repr.plot.height = 8)\n",
        "\n",
        "# set number of images to plot\n",
        "n <- 21\n",
        "\n",
        "# Loop plotting over n images\n",
        "layout(matrix(1:n, ncol = 7), respect = FALSE)\n",
        "for(i in 1:n){\n",
        "  plot_raster_image(cifar10$train$x[i,,,],\n",
        "                    cifar_labels[cifar10$train$y[i] + 1],\n",
        "                    max_value = 255)\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J45CSuRGtH6T"
      },
      "source": [
        "**Now that we've got a dataset, use what you've learned in this lab to build a model for classifying these images.**\n",
        "* Don't forget to pre-process your data\n",
        "* Stick to the same model structure as before\n",
        "* Remember to **check our input shape as it's different from the fashion mnist dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TO DO - Build a model to classify CIFAR-10 images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz0PaBlFbkAf"
      },
      "source": [
        "## E2.3 Solution\n",
        "\n",
        "The solution for the exercise can be found [here](https://colab.research.google.com/github/rses-dl-course/rses-dl-course.github.io/blob/master/notebooks/R/solutions/E.2.3.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnFU-5KjbkAf"
      },
      "source": [
        "# Notice\n",
        "Remember to enable GPU to make everything run faster (Runtime -> Change runtime type -> Hardware accelerator -> GPU).\n",
        "Also, if you run into trouble, simply reset the entire environment and start from the beginning:\n",
        "*   Edit -> Clear all outputs\n",
        "*   Runtime -> Reset all runtimes"
      ]
    }
  ]
}